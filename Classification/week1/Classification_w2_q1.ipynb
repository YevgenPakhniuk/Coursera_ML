{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load review dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv('c://users/evgeniy.pahnuk/Desktop/Coursera/Classification/week2/amazon_baby_subset.csv')\n",
    "products = products.fillna({'review':''}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Stop Pacifier Sucking without tears with Thumb...\n",
       "1      Nature's Lullabies Second Year Sticker Calendar\n",
       "2      Nature's Lullabies Second Year Sticker Calendar\n",
       "3                          Lamaze Peekaboo, I Love You\n",
       "4    SoftPlay Peek-A-Boo Where's Elmo A Children's ...\n",
       "5                            Our Baby Girl Memory Book\n",
       "6    Hunnt&reg; Falling Flowers and Birds Kids Nurs...\n",
       "7    Blessed By Pope Benedict XVI Divine Mercy Full...\n",
       "8    Cloth Diaper Pins Stainless Steel Traditional ...\n",
       "9    Cloth Diaper Pins Stainless Steel Traditional ...\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(10)['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of positive reviews = 26579\n",
      "# of negative reviews = 26493\n"
     ]
    }
   ],
   "source": [
    "print ('# of positive reviews =', len(products[products['sentiment']==1]))\n",
    "print ('# of negative reviews =', len(products[products['sentiment']==-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply text cleaning on the review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('c://users/evgeniy.pahnuk/Desktop/Coursera/Classification/week2/important_words.json', 'r') as f: # Reads the list of most frequent words\n",
    "    important_words = json.load(f)\n",
    "important_words = [str(s) for s in important_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    new_text = text\n",
    "    for i in string.punctuation:\n",
    "        new_text = new_text.str.replace(i, '')\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products['review_clean'] = remove_punctuation(products['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in important_words:\n",
    "    #products[word] = products['review_clean'].str.count(str(word))\n",
    "    products[word] = products['review_clean'].apply(lambda s : s.split().count(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53072, 198)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>baby</th>\n",
       "      <th>one</th>\n",
       "      <th>great</th>\n",
       "      <th>love</th>\n",
       "      <th>use</th>\n",
       "      <th>...</th>\n",
       "      <th>seems</th>\n",
       "      <th>picture</th>\n",
       "      <th>completely</th>\n",
       "      <th>wish</th>\n",
       "      <th>buying</th>\n",
       "      <th>babies</th>\n",
       "      <th>won</th>\n",
       "      <th>tub</th>\n",
       "      <th>almost</th>\n",
       "      <th>either</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  All of my kids have cried non-stop when I trie...       5          1   \n",
       "\n",
       "                                        review_clean  baby  one  great  love  \\\n",
       "0  All of my kids have cried nonstop when I tried...     0    0      1     0   \n",
       "\n",
       "   use   ...    seems  picture  completely  wish  buying  babies  won  tub  \\\n",
       "0    0   ...        0        0           0     0       0       0    0    0   \n",
       "\n",
       "   almost  either  \n",
       "0       0       0  \n",
       "\n",
       "[1 rows x 198 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products['contains_perfect'] = products['perfect'].apply(lambda perfect : +1 if perfect > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2955"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(products['contains_perfect'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert SFrame to NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe, features, label):\n",
    "    data_sframe['intercept'] = 1\n",
    "    features = ['intercept'] + features\n",
    "    features_sframe = data_sframe[features]\n",
    "    feature_matrix = features_sframe.as_matrix()\n",
    "    label_sarray = data_sframe[label]\n",
    "    label_array = np.array(label_sarray)\n",
    "    return(feature_matrix, label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix, sentiment = get_numpy_data(products, important_words, 'sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53072, 194)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating conditional probability with link function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "produces probablistic estimate for P(y_i = +1 | x_i, w).\n",
    "estimate ranges between 0 and 1.\n",
    "'''\n",
    "def predict_probability(feature_matrix, coefficients):\n",
    "    # Take dot product of feature_matrix and coefficients  \n",
    "    scores = np.dot(feature_matrix,coefficients)\n",
    "    # Compute P(y_i = +1 | x_i, w) using the link function\n",
    "    predictions = 1/( 1+np.exp(-scores) )\n",
    "    # return predictions\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_predictions           = [ 0.98201379  0.26894142]\n",
      "output of predict_probability = [ 0.98201379  0.26894142]\n"
     ]
    }
   ],
   "source": [
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),          1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_predictions = np.array( [ 1./(1+np.exp(-correct_scores[0])), 1./(1+np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "print ('The following outputs must match ')\n",
    "print ('------------------------------------------------')\n",
    "print ('correct_predictions           =', correct_predictions)\n",
    "print ('output of predict_probability =', predict_probability(dummy_feature_matrix, dummy_coefficients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute derivative of log likelihood with respect to a single coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):     \n",
    "    # Compute the dot product of errors and feature\n",
    "    derivative = np.dot(errors, feature)\n",
    "    # Return the derivative\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix, sentiment, coefficients):\n",
    "    indicator = (sentiment==+1)\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    logexp = np.log(1. + np.exp(-scores))\n",
    "    \n",
    "    # Simple check to prevent overflow\n",
    "    mask = np.isinf(logexp)\n",
    "    logexp[mask] = -scores[mask]\n",
    "    \n",
    "    lp = np.sum((indicator-1)*scores - logexp)\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_log_likelihood           = -5.33141161544\n",
      "output of compute_log_likelihood = -5.33141161544\n"
     ]
    }
   ],
   "source": [
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "dummy_sentiment = np.array([-1, 1])\n",
    "\n",
    "correct_indicators  = np.array( [ -1==+1,                                       1==+1 ] )\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),                     1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_first_term  = np.array( [ (correct_indicators[0]-1)*correct_scores[0],  (correct_indicators[1]-1)*correct_scores[1] ] )\n",
    "correct_second_term = np.array( [ np.log(1. + np.exp(-correct_scores[0])),      np.log(1. + np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "correct_ll          =      sum( [ correct_first_term[0]-correct_second_term[0], correct_first_term[1]-correct_second_term[1] ] ) \n",
    "\n",
    "print ('The following outputs must match ')\n",
    "print ('------------------------------------------------')\n",
    "print ('correct_log_likelihood           =', correct_ll)\n",
    "print ('output of compute_log_likelihood =', compute_log_likelihood(dummy_feature_matrix, dummy_sentiment, dummy_coefficients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking gradient steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter):\n",
    "    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n",
    "    for itr in range(0, max_iter):\n",
    "\n",
    "        # Predict P(y_i = +1|x_i,w) using your predict_probability() function\n",
    "        # YOUR CODE HERE\n",
    "        predictions = predict_probability(feature_matrix, initial_coefficients)\n",
    "        \n",
    "        # Compute indicator value for (y_i = +1)\n",
    "        indicator = (sentiment==+1)\n",
    "        \n",
    "        # Compute the errors as indicator - predictions\n",
    "        errors = indicator - predictions\n",
    "        for j in range(0, len(coefficients)): # loop over each coefficient\n",
    "            \n",
    "            # Recall that feature_matrix[:,j] is the feature column associated with coefficients[j].\n",
    "            # Compute the derivative for coefficients[j]. Save it in a variable called derivative\n",
    "            # YOUR CODE HERE\n",
    "            derivative = sum(feature_matrix[:,j]*errors)\n",
    "            \n",
    "            # add the step size times the derivative to the current coefficient\n",
    "            ## YOUR CODE HERE\n",
    "            coefficients[j] += step_size*derivative\n",
    "        \n",
    "        # Checking whether log likelihood is increasing\n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp = compute_log_likelihood(feature_matrix, sentiment, coefficients)\n",
    "            print ('iteration %*d: log likelihood of observed labels = %.8f' % \\\n",
    "                (int(np.ceil(np.log10(max_iter))), itr, lp))\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -36780.91768478\n",
      "iteration   1: log likelihood of observed labels = -36775.13127954\n",
      "iteration   2: log likelihood of observed labels = -36769.34795095\n",
      "iteration   3: log likelihood of observed labels = -36763.56769899\n",
      "iteration   4: log likelihood of observed labels = -36757.79052366\n",
      "iteration   5: log likelihood of observed labels = -36752.01642492\n",
      "iteration   6: log likelihood of observed labels = -36746.24540276\n",
      "iteration   7: log likelihood of observed labels = -36740.47745714\n",
      "iteration   8: log likelihood of observed labels = -36734.71258803\n",
      "iteration   9: log likelihood of observed labels = -36728.95079539\n",
      "iteration  10: log likelihood of observed labels = -36723.19207918\n",
      "iteration  11: log likelihood of observed labels = -36717.43643934\n",
      "iteration  12: log likelihood of observed labels = -36711.68387583\n",
      "iteration  13: log likelihood of observed labels = -36705.93438858\n",
      "iteration  14: log likelihood of observed labels = -36700.18797754\n",
      "iteration  15: log likelihood of observed labels = -36694.44464262\n",
      "iteration  20: log likelihood of observed labels = -36665.77410742\n",
      "iteration  30: log likelihood of observed labels = -36608.66369535\n",
      "iteration  40: log likelihood of observed labels = -36551.86072283\n",
      "iteration  50: log likelihood of observed labels = -36495.36502431\n",
      "iteration  60: log likelihood of observed labels = -36439.17638957\n",
      "iteration  70: log likelihood of observed labels = -36383.29456460\n",
      "iteration  80: log likelihood of observed labels = -36327.71925271\n",
      "iteration  90: log likelihood of observed labels = -36272.45011567\n",
      "iteration 100: log likelihood of observed labels = -36217.48677511\n",
      "iteration 200: log likelihood of observed labels = -35684.56313478\n",
      "iteration 300: log likelihood of observed labels = -35181.56106069\n"
     ]
    }
   ],
   "source": [
    "coefficients = logistic_regression(feature_matrix, sentiment, initial_coefficients=np.zeros(194),\n",
    "                                   step_size=1e-7, max_iter=301)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the scores as a dot product between feature_matrix and coefficients.\n",
    "scores = np.dot(feature_matrix, coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products['preds'] = pd.Series(scores).apply(lambda scores: +1 if scores > 0 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>baby</th>\n",
       "      <th>one</th>\n",
       "      <th>great</th>\n",
       "      <th>love</th>\n",
       "      <th>use</th>\n",
       "      <th>...</th>\n",
       "      <th>completely</th>\n",
       "      <th>wish</th>\n",
       "      <th>buying</th>\n",
       "      <th>babies</th>\n",
       "      <th>won</th>\n",
       "      <th>tub</th>\n",
       "      <th>almost</th>\n",
       "      <th>either</th>\n",
       "      <th>contains_perfect</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>31674</td>\n",
       "      <td>31724</td>\n",
       "      <td>31724</td>\n",
       "      <td>31724</td>\n",
       "      <td>31724</td>\n",
       "      <td>31724</td>\n",
       "      <td>31724</td>\n",
       "      <td>31724</td>\n",
       "      <td>31724</td>\n",
       "      <td>31724</td>\n",
       "      <td>...</td>\n",
       "      <td>31724</td>\n",
       "      <td>31724</td>\n",
       "      <td>31724</td>\n",
       "      <td>31724</td>\n",
       "      <td>31724</td>\n",
       "      <td>31724</td>\n",
       "      <td>31724</td>\n",
       "      <td>31724</td>\n",
       "      <td>31724</td>\n",
       "      <td>31724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21308</td>\n",
       "      <td>21348</td>\n",
       "      <td>21348</td>\n",
       "      <td>21348</td>\n",
       "      <td>21348</td>\n",
       "      <td>21348</td>\n",
       "      <td>21348</td>\n",
       "      <td>21348</td>\n",
       "      <td>21348</td>\n",
       "      <td>21348</td>\n",
       "      <td>...</td>\n",
       "      <td>21348</td>\n",
       "      <td>21348</td>\n",
       "      <td>21348</td>\n",
       "      <td>21348</td>\n",
       "      <td>21348</td>\n",
       "      <td>21348</td>\n",
       "      <td>21348</td>\n",
       "      <td>21348</td>\n",
       "      <td>21348</td>\n",
       "      <td>21348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        name  review  rating  sentiment  review_clean   baby    one  great  \\\n",
       "preds                                                                        \n",
       "-1     31674   31724   31724      31724         31724  31724  31724  31724   \n",
       " 1     21308   21348   21348      21348         21348  21348  21348  21348   \n",
       "\n",
       "        love    use    ...      completely   wish  buying  babies    won  \\\n",
       "preds                  ...                                                 \n",
       "-1     31724  31724    ...           31724  31724   31724   31724  31724   \n",
       " 1     21348  21348    ...           21348  21348   21348   21348  21348   \n",
       "\n",
       "         tub  almost  either  contains_perfect  intercept  \n",
       "preds                                                      \n",
       "-1     31724   31724   31724             31724      31724  \n",
       " 1     21348   21348   21348             21348      21348  \n",
       "\n",
       "[2 rows x 200 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.groupby(by=('preds')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>baby</th>\n",
       "      <th>one</th>\n",
       "      <th>great</th>\n",
       "      <th>love</th>\n",
       "      <th>use</th>\n",
       "      <th>would</th>\n",
       "      <th>...</th>\n",
       "      <th>completely</th>\n",
       "      <th>wish</th>\n",
       "      <th>buying</th>\n",
       "      <th>babies</th>\n",
       "      <th>won</th>\n",
       "      <th>tub</th>\n",
       "      <th>almost</th>\n",
       "      <th>either</th>\n",
       "      <th>contains_perfect</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">-1</th>\n",
       "      <th>-1</th>\n",
       "      <td>22206</td>\n",
       "      <td>22235</td>\n",
       "      <td>22235</td>\n",
       "      <td>22235</td>\n",
       "      <td>22235</td>\n",
       "      <td>22235</td>\n",
       "      <td>22235</td>\n",
       "      <td>22235</td>\n",
       "      <td>22235</td>\n",
       "      <td>22235</td>\n",
       "      <td>...</td>\n",
       "      <td>22235</td>\n",
       "      <td>22235</td>\n",
       "      <td>22235</td>\n",
       "      <td>22235</td>\n",
       "      <td>22235</td>\n",
       "      <td>22235</td>\n",
       "      <td>22235</td>\n",
       "      <td>22235</td>\n",
       "      <td>22235</td>\n",
       "      <td>22235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9468</td>\n",
       "      <td>9489</td>\n",
       "      <td>9489</td>\n",
       "      <td>9489</td>\n",
       "      <td>9489</td>\n",
       "      <td>9489</td>\n",
       "      <td>9489</td>\n",
       "      <td>9489</td>\n",
       "      <td>9489</td>\n",
       "      <td>9489</td>\n",
       "      <td>...</td>\n",
       "      <td>9489</td>\n",
       "      <td>9489</td>\n",
       "      <td>9489</td>\n",
       "      <td>9489</td>\n",
       "      <td>9489</td>\n",
       "      <td>9489</td>\n",
       "      <td>9489</td>\n",
       "      <td>9489</td>\n",
       "      <td>9489</td>\n",
       "      <td>9489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>-1</th>\n",
       "      <td>4255</td>\n",
       "      <td>4258</td>\n",
       "      <td>4258</td>\n",
       "      <td>4258</td>\n",
       "      <td>4258</td>\n",
       "      <td>4258</td>\n",
       "      <td>4258</td>\n",
       "      <td>4258</td>\n",
       "      <td>4258</td>\n",
       "      <td>4258</td>\n",
       "      <td>...</td>\n",
       "      <td>4258</td>\n",
       "      <td>4258</td>\n",
       "      <td>4258</td>\n",
       "      <td>4258</td>\n",
       "      <td>4258</td>\n",
       "      <td>4258</td>\n",
       "      <td>4258</td>\n",
       "      <td>4258</td>\n",
       "      <td>4258</td>\n",
       "      <td>4258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17053</td>\n",
       "      <td>17090</td>\n",
       "      <td>17090</td>\n",
       "      <td>17090</td>\n",
       "      <td>17090</td>\n",
       "      <td>17090</td>\n",
       "      <td>17090</td>\n",
       "      <td>17090</td>\n",
       "      <td>17090</td>\n",
       "      <td>17090</td>\n",
       "      <td>...</td>\n",
       "      <td>17090</td>\n",
       "      <td>17090</td>\n",
       "      <td>17090</td>\n",
       "      <td>17090</td>\n",
       "      <td>17090</td>\n",
       "      <td>17090</td>\n",
       "      <td>17090</td>\n",
       "      <td>17090</td>\n",
       "      <td>17090</td>\n",
       "      <td>17090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name  review  rating  review_clean   baby    one  great  \\\n",
       "preds sentiment                                                             \n",
       "-1    -1         22206   22235   22235         22235  22235  22235  22235   \n",
       "       1          9468    9489    9489          9489   9489   9489   9489   \n",
       " 1    -1          4255    4258    4258          4258   4258   4258   4258   \n",
       "       1         17053   17090   17090         17090  17090  17090  17090   \n",
       "\n",
       "                  love    use  would    ...      completely   wish  buying  \\\n",
       "preds sentiment                         ...                                  \n",
       "-1    -1         22235  22235  22235    ...           22235  22235   22235   \n",
       "       1          9489   9489   9489    ...            9489   9489    9489   \n",
       " 1    -1          4258   4258   4258    ...            4258   4258    4258   \n",
       "       1         17090  17090  17090    ...           17090  17090   17090   \n",
       "\n",
       "                 babies    won    tub  almost  either  contains_perfect  \\\n",
       "preds sentiment                                                           \n",
       "-1    -1          22235  22235  22235   22235   22235             22235   \n",
       "       1           9489   9489   9489    9489    9489              9489   \n",
       " 1    -1           4258   4258   4258    4258    4258              4258   \n",
       "       1          17090  17090  17090   17090   17090             17090   \n",
       "\n",
       "                 intercept  \n",
       "preds sentiment             \n",
       "-1    -1             22235  \n",
       "       1              9489  \n",
       " 1    -1              4258  \n",
       "       1             17090  \n",
       "\n",
       "[4 rows x 199 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.groupby(by=('preds', 'sentiment')).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "# Reviews   correctly classified = 39325\n",
      "# Reviews incorrectly classified = 13747\n",
      "# Reviews total                  = 53072\n",
      "-----------------------------------------------------\n",
      "Accuracy = 0.74\n"
     ]
    }
   ],
   "source": [
    "num_mistakes = len(products[products['sentiment'] != products['preds']]) # YOUR CODE HERE\n",
    "accuracy = 1 - num_mistakes/len(products) # YOUR CODE HERE\n",
    "print (\"-----------------------------------------------------\")\n",
    "print ('# Reviews   correctly classified =', len(products) - num_mistakes)\n",
    "print ('# Reviews incorrectly classified =', num_mistakes)\n",
    "print ('# Reviews total                  =', len(products))\n",
    "print (\"-----------------------------------------------------\")\n",
    "print ('Accuracy = %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which words contribute most to positive & negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefficients = list(coefficients[1:]) # exclude intercept\n",
    "word_coefficient_tuples = [(word, coefficient) for word, coefficient in zip(important_words, coefficients)]\n",
    "word_coefficient_tuples = sorted(word_coefficient_tuples, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.069275149999999647),\n",
       " ('love', 0.069004250000000072),\n",
       " ('easy', 0.06748420000000005),\n",
       " ('little', 0.046790450000000261),\n",
       " ('loves', 0.046414200000000044),\n",
       " ('well', 0.030355849999999917),\n",
       " ('perfect', 0.030355849999999917),\n",
       " ('old', 0.020272350000000126),\n",
       " ('nice', 0.018481399999999922),\n",
       " ('soft', 0.017954649999999985)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coefficient_tuples[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('return', -0.027977950000000137),\n",
       " ('monitor', -0.028324099999999935),\n",
       " ('disappointed', -0.030054849999999821),\n",
       " ('back', -0.031589949999999895),\n",
       " ('even', -0.03347119999999984),\n",
       " ('get', -0.03396785000000007),\n",
       " ('work', -0.036195249999999971),\n",
       " ('money', -0.04141760000000029),\n",
       " ('product', -0.047452650000000124),\n",
       " ('would', -0.063811999999999619)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coefficient_tuples[-10:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
